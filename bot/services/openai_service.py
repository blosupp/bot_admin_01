from openai import AsyncOpenAI
from bot.config import OPENAI_API_KEY
from database.crud import get_active_prompt
from database.db import AsyncSessionLocal

from sqlalchemy import delete, select
from database.models import Message


from database.crud import get_last_messages, add_message, get_user_memory_flag
from database.db import get_async_session

client = AsyncOpenAI(api_key=OPENAI_API_KEY)


async def generate_text(prompt: str, max_tokens: int = 700) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å GPT-4-turbo
    :param prompt: —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
    :param max_tokens: –º–∞–∫—Å. –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
    :return: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞
    """
    try:
        response = await client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –ø–æ —Ç–µ–º–µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"


async def generate_post_text(user_id: int) -> str:
    """
    –ë–µ—Ä—ë—Ç –∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –±–∞–∑—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ—Å—Ç.
    """
    async with AsyncSessionLocal() as session:
        prompt = await get_active_prompt(session, user_id)

    if not prompt or not prompt.text:
        return "‚ùå –£ —Ç–µ–±—è –Ω–µ –∑–∞–¥–∞–Ω –∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç. –£—Å—Ç–∞–Ω–æ–≤–∏ –µ–≥–æ –∫–æ–º–∞–Ω–¥–æ–π /prompt"

    return await generate_text(prompt.text)



async def generate_text_with_memory(user_id: int, new_user_text: str) -> str:
    async with get_async_session() as session:
        print(f"‚öôÔ∏è [user_id={user_id}] ‚Üí {new_user_text}")

        # üîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω–∞ –ª–∏ –ø–∞–º—è—Ç—å
        use_memory = await get_user_memory_flag(user_id, session)

        # üî∏ –ï—Å–ª–∏ –ø–∞–º—è—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏
        if not use_memory:
            return await generate_text(new_user_text)

        # üß† –ï—Å–ª–∏ –ø–∞–º—è—Ç—å –≤–∫–ª—é—á–µ–Ω–∞ ‚Äî —Å–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        history = await get_last_messages(session, user_id)
        print("üìö –ò—Å—Ç–æ—Ä–∏—è –∏–∑ –ë–î:", [(m.role, m.content[:30]) for m in history])

        messages = [{"role": "system", "content": "–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –≤–µ–¥–∏ –¥–∏–∞–ª–æ–≥ –∫—Ä–∞—Ç–∫–æ."}]
        for m in history:
            messages.append({"role": m.role, "content": m.content})
        messages.append({"role": "user", "content": new_user_text})

        try:
            response = await client.chat.completions.create(
                model="gpt-4-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=700
            )
            reply = response.choices[0].message.content.strip()

            print("üß† GPT –æ—Ç–≤–µ—Ç:", reply[:50])

            # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥
            await add_message(session, user_id, "user", new_user_text)
            await add_message(session, user_id, "assistant", reply)

            # üßπ –£–¥–∞–ª—è–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50
            subquery = (
                select(Message.id)
                .where(Message.user_id == user_id)
                .order_by(Message.id.desc())
                .limit(50)
            ).subquery()

            await session.execute(
                delete(Message)
                .where(Message.user_id == user_id)
                .where(Message.id.not_in(select(subquery.c.id)))
            )
            await session.commit()

            return reply

        except Exception as e:
            print("‚ùå GPT –æ—à–∏–±–∫–∞:", e)
            return f"‚ùå –û—à–∏–±–∫–∞: {e}"
